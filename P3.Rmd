---
title: "Untitled"
author: "Du Shi, Kunning Zhang, Yixuan Yin"
date: "2026-02-05"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
# normalization(train)
normalize_rows <- function(mat) mat / rowSums(mat)
features_train_norm <- lapply(features_train, normalize_rows)

eda_X <- do.call(rbind, features_train_norm)
eda_y <- rep(c("Human", "LLM"), sapply(features_train_norm, nrow))
```

```{r}
cat("Human texts:", nrow(features_train_norm[[1]]), "\n")
cat("LLM texts:", nrow(features_train_norm[[2]]), "\n")
cat("Number of function words:", ncol(eda_X), "\n\n")

```

```{r}
human_mean <- colMeans(features_train_norm[[1]])
llm_mean   <- colMeans(features_train_norm[[2]])

mean_diff <- human_mean - llm_mean
top <- order(abs(mean_diff), decreasing = TRUE)[1:10]

barplot(mean_diff[top],
        main = "Top 10 Function Words Mean Difference Between Human and LLM Texts",
        ylab = "Mean Difference")
```

```{r}
dist_mat <- dist(eda_X)
mds_res <- cmdscale(dist_mat)

plot(mds_res[,1], mds_res[,2],
     col = ifelse(eda_y == "Human", "blue", "red"),
     pch = 16,
     cex = 0.6,
     xlab = "MDS1",
     ylab = "MDS2",
     main = "MDS Visualisation of Stylometric Distances")


human_pts <- mds_res[eda_y == "Human", ]
llm_pts   <- mds_res[eda_y == "LLM", ]

points(colMeans(human_pts)[1], colMeans(human_pts)[2],
       pch = 4, cex = 2, lwd = 2)

points(colMeans(llm_pts)[1], colMeans(llm_pts)[2],
       pch = 4, cex = 2, lwd = 2)

legend("topright",
       legend = c("Human", "LLM"),
       col = c("blue", "red"),
       pch = 16)
```

```{r}
split_idx <- lapply(features, function(mat) {
  sample(1:nrow(mat), size = floor(0.8 * nrow(mat)))
})

features_train <- mapply(function(mat, idx) {
  mat[idx, ]
}, features, split_idx, SIMPLIFY = FALSE)

features_test <- mapply(function(mat, idx) {
  mat[-idx, ]
}, features, split_idx, SIMPLIFY = FALSE)

x <- NULL
for (i in 1:length(features_train)) {
  x <- rbind(x, apply(features_train[[i]], 2, sum))
}

for (i in 1:nrow(x)) {
x[i,] <- x[i,] / sum(x[i,])
}

for (j in 1:ncol(x)) {
x[,j] <- (x[,j]- mean(x[,j]))/sd(x[,j])
}

d <- dist(x)
pts <- cmdscale(d)

plot(pts, type="n", main="MDS Plot of Authors")
text(pts[,1], pts[,2], labels=authors)

```
下面是四元的 可删
```{r}
# Training-Test Sets
traindata <- features
testdata <- NULL
testlabels <- NULL

for (i in 1:length(traindata)) {

  testind <- sample(1:nrow(traindata[[i]]), 1)

  testdata <- rbind(testdata, traindata[[i]][testind,])
  testlabels <- c(testlabels, i)

  traindata[[i]] <- traindata[[i]][-testind,,drop=FALSE]
}

pred_da <- discriminantCorpus(traindata, testdata)
acc_da <- sum(pred_da == testlabels) / length(testlabels)

pred_knn <- myKNN(traindata, testdata)
acc_knn <- sum(pred_knn == testlabels) / length(testlabels)

cat("\nTest Accuracy:\n")
cat("Discriminant Analysis:", acc_da, "\n")
cat("KNN:", acc_knn, "\n")
```

```{r}
# Cross-Validation
predictions_da <- NULL
predictions_knn <- NULL
truth <- NULL

for (i in 1:length(features)) {
  for (j in 1:nrow(features[[i]])) {
    testdata <- matrix(features[[i]][j,], nrow=1)
    traindata <- features
    traindata[[i]] <- traindata[[i]][-j,,drop=FALSE]

    pred <- discriminantCorpus(traindata, testdata)
    predictions_da <- c(predictions_da, pred)

    pred <- myKNN(traindata, testdata)
    predictions_knn <- c(predictions_knn, pred)
    truth <- c(truth, i)
  }
}

acc_da_cv  <- sum(predictions_da  == truth) / length(truth)
acc_knn_cv <- sum(predictions_knn == truth) / length(truth)

cat("\nCross-Validation Accuracy:\n")
cat("Discriminant Analysis:", acc_da_cv, "\n")
cat("KNN:", acc_knn_cv, "\n")

# Confusion matrices
cat("\nDiscriminant Analysis Confusion Matrix:\n")
print(confusionMatrix(as.factor(predictions_da), as.factor(truth)))

cat("\nKNN Confusion Matrix:\n")
print(confusionMatrix(as.factor(predictions_knn), as.factor(truth)))
```
下面是二元的
```{r}
human_index <- which(authors == "Human")

human_data <- features[[human_index]]

llm_data <- NULL
for (i in 1:length(features)) {
  if (i != human_index) {
    llm_data <- rbind(llm_data, features[[i]])
  }
}
features_bin <- list(human_data, llm_data)
```

```{r}
# Training-Test Sets
traindata <- features_bin
testdata <- NULL
testlabels <- NULL

for (i in 1:length(traindata)) {

  testind <- sample(1:nrow(traindata[[i]]), 1)

  testdata <- rbind(testdata, traindata[[i]][testind,])
  testlabels <- c(testlabels, i)

  traindata[[i]] <- traindata[[i]][-testind,,drop=FALSE]
}

pred_da <- discriminantCorpus(traindata, testdata)
acc_da <- sum(pred_da == testlabels) / length(testlabels)

pred_knn <- myKNN(traindata, testdata)
acc_knn <- sum(pred_knn == testlabels) / length(testlabels)

cat("\nBinary Test Accuracy:\n")
cat("Discriminant Analysis:", acc_da, "\n")
cat("KNN:", acc_knn, "\n")
```

```{r}
# Cross-Validation
predictions_da <- NULL
predictions_knn <- NULL
truth <- NULL

for (i in 1:length(features_bin)) {
  for (j in 1:nrow(features_bin[[i]])) {

    testdata <- matrix(features_bin[[i]][j,], nrow=1)

    traindata <- features_bin
    traindata[[i]] <- traindata[[i]][-j,,drop=FALSE]

    pred <- discriminantCorpus(traindata, testdata)
    predictions_da <- c(predictions_da, pred)

    pred <- myKNN(traindata, testdata)
    predictions_knn <- c(predictions_knn, pred)

    truth <- c(truth, i)
  }
}

acc_da_cv  <- sum(predictions_da  == truth) / length(truth)
acc_knn_cv <- sum(predictions_knn == truth) / length(truth)

cat("\nBinary Cross-Validation Accuracy:\n")
cat("Discriminant Analysis:", acc_da_cv, "\n")
cat("KNN:", acc_knn_cv, "\n")

# Confusion matrices
cat("\nBinary Discriminant Analysis Confusion Matrix:\n")
print(confusionMatrix(as.factor(predictions_da), as.factor(truth)))

cat("\nBinary KNN Confusion Matrix:\n")
print(confusionMatrix(as.factor(predictions_knn), as.factor(truth)))

```

## KNN

```{r}
# k values
k_vals <- 1:20

# plot accuracy vs k
plot(k_vals, k_analysis,
     type = "b",      
     pch = 19,
     xlab = "k (number of neighbors)",
     ylab = "Cross-validated accuracy",
     main = "KNN Accuracy")

# optional grid for readability
grid()


```





```{r}
knn_loo_table <- data.frame(
  Metric = c("Accuracy", "Kappa",
             "Human Recall (Sensitivity)",
             "AI Recall (Specificity)",
             "Balanced Accuracy"),
  Value = c(
    cm_knn_loo$overall["Accuracy"],
    cm_knn_loo$overall["Kappa"],
    cm_knn_loo$byClass["Sensitivity"],
    cm_knn_loo$byClass["Specificity"],
    cm_knn_loo$byClass["Balanced Accuracy"]
  )
)

knitr::kable(knn_loo_table,
             digits = 3,
             caption = "LOOCV Performance of k-NN (k = 2)")

knitr::kable(cm_knn_loo$table,
             caption = "Confusion Matrix")


```





