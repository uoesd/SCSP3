---
title: "Untitled"
author: "Du Shi, Kunning Zhang, Yixuan Yin"
date: "2026-02-05"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
source("code.R")
```

# Brief Introduction 



# Data preprocessing
The dataset contains around 3,500 complete English language text presented in Stylometry form, grouped by author: Human, ChatGPT, Gemini and Llama. To slove this task, all large language model (LLM) were merged into a single category, resulting in a binary dataset of Human vs LLM. Then the data were randomly split into 80% training sets and 20% testing sets, and the texts were normalised to ensure comparability across texts of different lengths. Finally, The normalised 80% training set was used for exploratory data analysis.

# Exploratory Data Analysis

```{r}
# normalization(train)
normalize_rows <- function(mat) mat / rowSums(mat)
features_train_norm <- lapply(features_train, normalize_rows)

eda_X <- do.call(rbind, features_train_norm)
eda_y <- rep(c("Human", "LLM"), sapply(features_train_norm, nrow))




d1 <- data.frame("Human texts" = nrow(features_train_norm[[1]]),
                  "LLM texts" = nrow(features_train_norm[[2]]),
                  "Function words" = ncol(eda_X),
                  check.names = FALSE)
d1
```

```{r}
human_mean <- colMeans(features_train_norm[[1]])
llm_mean   <- colMeans(features_train_norm[[2]])

mean_diff <- human_mean - llm_mean
top <- order(abs(mean_diff), decreasing = TRUE)[1:10]

barplot(mean_diff[top],
        main = "Top 10 Function Words Mean Difference Between Human and LLM Texts",
        ylab = "Mean Difference")
```


```{r}
dist_mat <- dist(eda_X)
mds_res  <- cmdscale(dist_mat)

plot(mds_res[,1], mds_res[,2],
     col = ifelse(eda_y == "Human", "blue", "red"),
     pch = 16,
     cex = 0.6,
     xlab = "MDS1",
     ylab = "MDS2",
     main = "MDS Visualisation of Stylometric Distances")

human_cent <- colMeans(mds_res[eda_y == "Human", ])
llm_cent   <- colMeans(mds_res[eda_y == "LLM", ])

points(human_cent[1], human_cent[2], pch = 4, cex = 2, lwd = 2, col = "blue")
points(llm_cent[1], llm_cent[2], pch = 4, cex = 2, lwd = 2, col = "Black")

legend("topright",
       legend = c("Human texts", "LLM texts", "Human centroid", "LLM centroid"),
       col = c("blue", "red", "blue", "Black"),
       pch = c(16, 16, 4, 4),
       pt.cex = c(0.8, 0.8, 2, 2),
       bty = "n")
```

```{r}
split_idx <- lapply(features, function(mat) {
  sample(1:nrow(mat), size = floor(0.8 * nrow(mat)))
})

features_train <- mapply(function(mat, idx) {
  mat[idx, ]
}, features, split_idx, SIMPLIFY = FALSE)

features_test <- mapply(function(mat, idx) {
  mat[-idx, ]
}, features, split_idx, SIMPLIFY = FALSE)

x <- NULL
for (i in 1:length(features_train)) {
  x <- rbind(x, apply(features_train[[i]], 2, sum))
}

for (i in 1:nrow(x)) {
x[i,] <- x[i,] / sum(x[i,])
}

for (j in 1:ncol(x)) {
x[,j] <- (x[,j]- mean(x[,j]))/sd(x[,j])
}

d <- dist(x)
pts <- cmdscale(d)

plot(pts, type="n", main="MDS Plot of Authors")
text(pts[,1], pts[,2], labels=authors)

```


# Model Choice

## DA
```{r}
knitr::kable(da_loo_table, digits = 3,
             caption = "DA Performance — LOOCV")

```

```{r}

knitr::kable(cm_da_loo$table,
             caption = "DA (LOOCV)")
```

## KNN

```{r}
# k values
k_vals <- 1:20

# plot accuracy vs k
plot(k_vals, k_analysis,
     type = "b",      
     pch = 19,
     xlab = "k (number of neighbors)",
     ylab = "Cross-validated accuracy",
     main = "KNN Accuracy")

# optional grid for readability
grid()


```





```{r}
knn_loo_table <- data.frame(
  Metric = c("Accuracy", "Kappa",
             "Human Recall (Sensitivity)",
             "AI Recall (Specificity)",
             "Balanced Accuracy"),
  Value = c(
    cm_knn_loo$overall["Accuracy"],
    cm_knn_loo$overall["Kappa"],
    cm_knn_loo$byClass["Sensitivity"],
    cm_knn_loo$byClass["Specificity"],
    cm_knn_loo$byClass["Balanced Accuracy"]
  )
)

knitr::kable(knn_loo_table,
             digits = 3,
             caption = "LOOCV Performance of k-NN (k = 2)")
```


```{r}
knitr::kable(cm_knn_loo$table,
             caption = "Confusion Matrix")


```


```{r}

knitr::kable(loo_knn_cm$table,
             caption = "Confusion Matrix")
```
# Testing Results

```{r}

knitr::kable(da_test_table, digits = 3,
             caption = "DA Performance — Test Set")
```


```{r}

knitr::kable(cm_da_test$table,
             caption = "DA (Test)")

```
